---
title: "Case-Control Studies"
date: 2025-10-28
summary: "A case-control study starts by identifying people with an outcome (cases) and a comparable group without it (controls), then looks backward to see how their exposures differ. This design is typically retrospective. For example, researchers might take 100 patients with lung cancer (cases) and 100 similar patients without cancer (controls) to investigate past exposures (like asbestos). The key feature is that the study goes from outcome (disease) to exposure. Case-control studies are efficient for rare diseases and can study multiple exposures, but they require careful control selection to avoid bias."
---

A case-control study starts by identifying people with an outcome (cases) and a comparable group without it (controls), then looks backward to see how their exposures differ. This design is typically retrospective. For example, researchers might take 100 patients with lung cancer (cases) and 100 similar patients without cancer (controls) to investigate past exposures (like asbestos). The key feature is that the study goes from outcome (disease) to exposure. Case-control studies are efficient for rare diseases and can study multiple exposures, but they require careful control selection to avoid bias.

Case Definition: Ensure the cases have a clear, consistent definition. Ideally, all cases should be newly diagnosed (incident cases) during a specific time frame. Verify inclusion/exclusion criteria. The appraisal tool asks if “cases were clearly defined”,  Poorly defined cases (e.g. mixing different disease severities) weaken the study.

Control Selection: Controls must come from the same source population as cases,  Ask: if a control got the disease, could they have been included as a case? Controls should have had the same chance to become a case. This avoids selection bias. For example, if cases are hospital patients, controls could be other hospital patients with unrelated conditions, or community members, but not patients from a different region or time period. The NHLBI guide stresses that controls should be from the “same or similar population” as cases,

Matching and Confounders: Many case-controls use matching (e.g. each case paired to a control of same age/sex) to balance confounders. If matching is used, the analysis must account for it (e.g. matched odds ratios). If not matched, check that analysis adjusts for confounders statistically. The appraisal tool specifically asks if “key confounders were measured and adjusted”,  For example, in a lung cancer study, smoking is a major confounder that should be controlled.

Exposure Measurement: Since both cases and controls are interviewed or assessed about past exposures, measurement methods must be the same in both groups. Look for blind assessment of exposure (interviewers unaware of case/control status) to reduce interviewer bias. Also, exposures should be clearly defined and measured similarly (same questionnaire, same medical records),

Recall Bias: Unlike cohort studies, case-controls are susceptible to recall bias: cases may remember exposures differently after diagnosis. Appraise whether the study tried to minimize this (e.g. using objective records rather than asking memory).

Sample Size Justification: Check if the study provided a rationale for the number of cases/controls (power calculation). Small studies may miss real effects.

Statistical Analysis: Case-control studies typically report odds ratios (OR) with confidence intervals. For rare diseases, OR approximates relative risk. Make sure CIs are given. Check that unmatched studies used logistic regression to adjust for confounders, and matched studies used matched analysis. Also, note if subgroup or sensitivity analyses were done.

Inappropriate Controls: A big red flag is controls that are not comparable to cases. For instance, using healthy volunteers as controls for a cancer study, when cases were hospitalized, can bias results. The guidance says controls should come from the same “source population”,  If a study fails this (e.g. controls from a different time period or place), bias is likely.

Selection Bias: If the study did not include all eligible cases or controls, it should use random sampling of the rest,  For example, if only 30% of eligible lung cancer patients were included (and it isn’t explained why), or controls were handpicked, trust is lost. The NHLBI tool notes random selection is preferred if not all are used,

Differential Exposure Measurement: Another red flag is measuring exposures differently. For example, if cases are interviewed in person but controls fill a mail survey, recall or social desirability bias differs. If exposure assessors knew who was a case, they might inadvertently influence answers. The tool asks if exposure was measured the same way and assessors blinded,

Recall Bias: This is inherent in retrospective designs. If possible, look for use of medical records or objective data to confirm exposures (rather than just memory). If cases know the study purpose (e.g. asbestos exposure and mesothelioma), they might over-report exposure compared to controls.

Confounding Not Addressed: Since case-control can’t rely on randomization, failing to adjust for confounders is a critical flaw,  Ensure the analysis controls for the most important confounders (often via multivariable models or stratification).

Overmatching: Sometimes studies match controls to cases on variables that are themselves related to the exposure, which can hide true effects. If matching is described, check whether the matched factors were properly adjusted in analysis (the guidance notes they should be),

Misinterpretation of OR: Remember that OR is not a direct measure of risk. A common mistake is treating it like a risk ratio without noting the disease’s prevalence. For rare outcomes OR ~ RR, but for common outcomes OR can overstate risk.

Consider a case-control study of 150 people with stroke (cases) and 150 without stroke (controls) examining prior use of medication X. To appraise it: first check cases and controls. Were the stroke patients all from the same time period and region? Did the controls come from that same community or from people admitted to the same hospital for unrelated issues? If controls were from a different city, that’s problematic. Next, look at exposure assessment – how did they determine who used medication X? If cases were asked face-to-face but controls answered an online survey, recall could differ. Ideally, the study should have used the same method for both. Also, did they account for confounders? If smoking affects both stroke risk and maybe medication use, the analysis should adjust for smoking. The appraisal checklist would note if they “measured and adjusted” for key factors,  Finally, note how results are reported: probably as an odds ratio (e.g. “cases had 2.5 times the odds of prior medication X use than controls (OR=2.5, 95% CI 1.4–4.5)”). That’s fine as long as it’s interpreted correctly.
